{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52aa616a-9b81-4e22-af2e-f1f5ec06db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in c:\\users\\ashis\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras_tuner) (3.8.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras_tuner) (24.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras_tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashis\\appdata\\roaming\\python\\python312\\site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2024.12.14)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from optree->keras->keras_tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ashis\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4382b09-f970-412b-b583-3666e776d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Input layer (assume image size 48x48x1 for grayscale)\n",
    "    model.add(layers.Input(shape=(48, 48, 1)))\n",
    "    \n",
    "    # First convolutional block\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Second convolutional block\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten and Dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Output layer (7 classes, for example)\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with a hyperparameter for learning rate\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2273e9-e144-4875-bdd8-8454aa830344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 19m 56s]\n",
      "val_accuracy: 0.5222903490066528\n",
      "\n",
      "Best val_accuracy So Far: 0.5533574819564819\n",
      "Total elapsed time: 01h 52m 45s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "96                |128               |conv_1_filters\n",
      "3                 |5                 |conv_1_kernel\n",
      "64                |64                |conv_2_filters\n",
      "5                 |5                 |conv_2_kernel\n",
      "64                |256               |dense_units\n",
      "0.2               |0.2               |dropout_rate\n",
      "0.0047338         |0.00023557        |learning_rate\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 85ms/step - accuracy: 0.2625 - loss: 1.8506 - val_accuracy: 0.3546 - val_loss: 1.6102\n",
      "Epoch 2/20\n",
      "\u001b[1m514/898\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 79ms/step - accuracy: 0.3684 - loss: 1.6120"
     ]
    }
   ],
   "source": [
    "# Create a tuner object\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # You can choose other objectives, e.g., val_loss\n",
    "    max_trials=10,             # Number of different hyperparameter combinations to try\n",
    "    executions_per_trial=1,    # How many models to build and fit for each trial (use >1 for more reliable estimates)\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='emotion_cnn'\n",
    ")\n",
    "\n",
    "# Print a summary of the search space\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Assume you have training and validation data generators or numpy arrays:\n",
    "# For example, if using ImageDataGenerator:\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'images/train/',\n",
    "    target_size=(48,48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'images/test/',\n",
    "    target_size=(48,48),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Run the hyperparameter search\n",
    "tuner.search(train_generator,\n",
    "             validation_data=val_generator,\n",
    "             epochs=20,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453817b6-1579-474d-adc9-3534da1a2d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
